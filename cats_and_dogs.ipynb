{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats and Dogs Problem Solution\n",
    "The inspiration for this script comes from a beautiful [keras blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Imports \n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "#Keras imports\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First divide train data into 3 parts - train, test, validation. \n",
    "#We are doing this for using ImageDataGenarator Class\n",
    "all_image_names = os.listdir('data/orig/train')\n",
    "shuffle(all_image_names)\n",
    "\n",
    "#Send shuffled data into different folders.\n",
    "l = len(all_image_names)\n",
    "train = all_image_names[:int(0.80*l)]\n",
    "validation = all_image_names[int(0.80*l):int(0.90*l)]\n",
    "test = all_image_names[int(0.90*l):]\n",
    "\n",
    "os.mkdir('data/new')\n",
    "os.mkdir('data/new/train')\n",
    "os.mkdir('data/new/train/cats/')\n",
    "os.mkdir('data/new/train/dogs')\n",
    "os.mkdir('data/new/validation')\n",
    "os.mkdir('data/new/validation/cats')\n",
    "os.mkdir('data/new/validation/dogs')\n",
    "os.mkdir('data/new/test')\n",
    "os.mkdir('data/new/test/cats')\n",
    "os.mkdir('data/new/test/dogs')\n",
    "\n",
    "#We must also dividing image into proper subfolders.\n",
    "#Another prerequisite for ImageDataGenerator Class\n",
    "\n",
    "for x in train:\n",
    "    if x.split('.')[0] == 'cat':\n",
    "        os.rename('data/orig/train/'+x , 'data/new/train/cats/'+x)\n",
    "    else:\n",
    "        os.rename('data/orig/train/'+x , 'data/new/train/dogs/'+x)\n",
    "for x in validation:\n",
    "    if x.split('.')[0] == 'cat':\n",
    "        os.rename('data/orig/train/'+x , 'data/new/validation/cats/'+x)\n",
    "    else:\n",
    "        os.rename('data/orig/train/'+x , 'data/new/validation/dogs/'+x)\n",
    "for x in test:\n",
    "    if x.split('.')[0] == 'cat':\n",
    "        os.rename('data/orig/train/'+x , 'data/new/test/cats/'+x)\n",
    "    else:\n",
    "        os.rename('data/orig/train/'+x , 'data/new/test/dogs/'+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Let us prepare our data\n",
    "train_conf = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "validation_conf = ImageDataGenerator(rescale=1./255) #Only scaling in test data\n",
    "\n",
    "\n",
    "train_generator = train_conf.flow_from_directory(\n",
    "        'data/new/train/',  #Target directory\n",
    "        target_size=(100, 100),  #All images will be resized to 150x150\n",
    "        batch_size=40,\n",
    "        class_mode='binary')  #We will later use binary_crossentropy loss, hence we need binary labels\n",
    "\n",
    "#Generator for validation data\n",
    "validation_generator = validation_conf.flow_from_directory(\n",
    "        'data/new/validation/',\n",
    "        target_size=(100, 100),\n",
    "        batch_size=40,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(100, 100, 3))) #Convo Layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "\n",
    "model.add(Convolution2D(32, 3, 3)) #Convo Layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3)) #Convo Layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#The model so far outputs 3D feature maps (height, width, features), we shall flatten those features\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64)) #Fully Connected Layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1)) #Fully Connected Output Layer\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compile our model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 97s - loss: 0.6354 - acc: 0.6352 - val_loss: 0.5245 - val_acc: 0.7513\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 92s - loss: 0.5430 - acc: 0.7316 - val_loss: 0.5174 - val_acc: 0.7625\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 94s - loss: 0.4929 - acc: 0.7676 - val_loss: 0.4247 - val_acc: 0.8150\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 90s - loss: 0.4591 - acc: 0.7867 - val_loss: 0.4757 - val_acc: 0.7813\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 91s - loss: 0.4394 - acc: 0.8017 - val_loss: 0.3637 - val_acc: 0.8475\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 92s - loss: 0.4187 - acc: 0.8136 - val_loss: 0.3895 - val_acc: 0.8275\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 92s - loss: 0.4027 - acc: 0.8229 - val_loss: 0.3389 - val_acc: 0.8488\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 92s - loss: 0.3914 - acc: 0.8311 - val_loss: 0.3860 - val_acc: 0.8325\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 92s - loss: 0.3768 - acc: 0.8405 - val_loss: 0.3791 - val_acc: 0.8388\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 92s - loss: 0.3724 - acc: 0.8430 - val_loss: 0.3922 - val_acc: 0.8288\n"
     ]
    }
   ],
   "source": [
    "#Let us fit data into the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=20000,\n",
    "        nb_epoch=10,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=800)\n",
    "model.save_weights('try_1.h5')  # saving weights after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras_tensorflow]",
   "language": "python",
   "name": "conda-env-keras_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
